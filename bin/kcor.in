#!/usr/bin/env python

import argparse
import datetime
from email.mime.text import MIMEText
import glob
import os
import pathlib
import psutil
import re
import shutil
import smtplib
import socket
import subprocess
import sys
import time

PY3 = sys.version_info[0] == 3

if PY3:
    import configparser
else:
    import ConfigParser as configparser

try:
    from astropy.io import fits
    from astropy.utils.exceptions import AstropyUserWarning
    ls_requirements = True
except ModuleNotFoundError as e:
    ls_requirements = False

try:
    import mysql
    import mysql.connector
    import packaging.specifiers
    import packaging.version
    versions_requirements = True
except ModuleNotFoundError as e:
    versions_requirements = False


# set to True to not launch real scripts
TEST = False

DEVNULL = open(os.devnull, "w")
PIPELINE_DIR = os.path.dirname(os.path.dirname(os.path.realpath(__file__)))

POLL_SECS = 0.5

LEVELS = ["DEBUG", "INFO", "WARN", "ERROR", "CRITICAL"]
LOG_DIR = "/hao/acos/kcor/logs"


intervals = (
    ("weeks", 604800),  # 60 * 60 * 24 * 7
    ("days", 86400),    # 60 * 60 * 24
    ("hrs", 3600),    # 60 * 60
    ("mins", 60),
    ("secs", 1),
    )

def display_time(seconds, granularity=2):
    result = []

    for name, count in intervals:
        value = seconds // count
        if value:
            seconds -= value * count
            if value == 1:
                name = name.rstrip("s")
            result.append("%d %s" % (value, name))
    return " ".join(result[:granularity])


def format_timedelta(timedelta):
    return(display_time(int(timedelta.total_seconds()), granularity=len(intervals)))


def convert_boolean(value):
    return True if value.lower() in {"1", "yes", "true"} else False


def notify_completed(args, task):
    config_basename = f"kcor.{args.flags}.cfg"

    # construct config file filename
    config_filename = os.path.join(PIPELINE_DIR, "config", config_basename)

    # read config file to get arguments to launch data/processing simulators
    config = configparser.ConfigParser()
    config.read(config_filename)

    try:
        send_notification = convert_boolean(config.get("notifications", "send"))
    except (configparser.NoSectionError, configparser.NoOptionError) as e:
        send_notification = False

    try:
        notification_email = config.get("notifications", "email")
    except (configparser.NoSectionError, configparser.NoOptionError) as e:
        send_notification = False

    if send_notification:
        userhome = os.path.expanduser("~")
        user = os.path.split(userhome)[-1]
        hostname = socket.gethostname()

        dates = ",".join(args.dates)

        with open(config_filename, "r") as f:
            text = f.read()

        msg = MIMEText(text)
        msg["Subject"] = f"KCor {task} ({args.flags}) job completed for {dates} on {hostname}"
        msg["From"] = f"{user}@ucar.edu"
        msg["To"] = notification_email

        s = smtplib.SMTP("localhost")
        s.send_message(msg)
        s.quit()


def increment_date(date):
    format = "%Y%m%d"
    d = datetime.datetime.strptime(date, format)
    d += datetime.timedelta(days=1)
    return(d.strftime(format))


def split_dates(date_expr, error):
    dates = []
    date_re = re.compile("^[12][0-9]{7}$")
    date_range_re = re.compile("^[12][0-9]{7}-[12][0-9]{7}$")
    for d in date_expr.split(","):
        if date_re.match(d):
            dates.append(d)
        elif date_range_re.match(d):
            start_date = d[0:8]
            end_date = d[9:17]
            if end_date <= start_date:
                error(f"end of range before start of range: {d}")
            date = start_date
            while date < end_date:
                dates.append(date)
                date = increment_date(date)
        else:
            error(f"invalid date expression: {d}")

    return(dates)


def get_login(flags, error):
    config_basename = f"kcor.{flags}.cfg"

    # construct config file filename
    config_filename = os.path.join(PIPELINE_DIR, "config", config_basename)
    if not os.path.isfile(config_filename):
        basename = os.path.basename(config_filename)
        error(f"configuration file does not exist: {basename}")

    kcor_config = configparser.ConfigParser()
    kcor_config.read(config_filename)

    try:
        mysql_config_filename = kcor_config.get("database", "config_filename")
        mysql_config_section = kcor_config.get("database", "config_section")
    except configparser.NoSectionError:
        args.parser.error("database information not specified")

    mysql_config = configparser.ConfigParser()
    mysql_config.read(mysql_config_filename)

    try:
        host = mysql_config.get(mysql_config_section, "host")
        user = mysql_config.get(mysql_config_section, "user")
        password = mysql_config.get(mysql_config_section, "password")
        port = mysql_config.get(mysql_config_section, "port")
        database = mysql_config.get(mysql_config_section, "database")
    except configparser.NoSectionError:
        args.parser.error("incomplete database information")

    return(host, user, password, port, database)


# list sub-command
def list_processes(args):
    kcor_processes = []
    for p in psutil.process_iter():
        cmdline = p.cmdline()
        cmdline = "" if len(cmdline) == 0 else cmdline[-1]
        if p.name() == "idl" and cmdline.startswith("kcor"):
            kcor_processes.append({"cmdline": cmdline,
                                   "pid": p.pid,
                                   "start_time": p.create_time()})
    if len(kcor_processes) == 0:
        print("no kcor processes currently running")
        return

    now = datetime.datetime.now()

    for p in kcor_processes:
        started = datetime.datetime.fromtimestamp(p["start_time"])
        time_running = format_timedelta(now - started)
        start_time = started.strftime("%Y-%m-%d %H:%M:%S")
        pid = p["pid"]
        cmdline = p["cmdline"]
        print(f"[{pid}] ({start_time} running {time_running}): {cmdline}")


# versions sub-command
def versions(args):
    if not versions_requirements:
        args.parser.error("missing Python packages required for querying database")

    dates = split_dates(",".join(args.dates), args.parser.error)
    host, user, password, port, database = get_login(args.flags, args.parser.error)

    versions_list = []
    try:
        connection = mysql.connector.connect(host=host, user=user, password=password)
        cursor = connection.cursor()
        for d in dates:
            versions_list.append(get_version(d, cursor))
    except mysql.connector.Error as e:
        print(e)
    finally:
        cursor.close()
        connection.close()

    filter = make_version_filter(args.filter)

    if args.oldest:
        f = [v for v in versions_list if v[1] is not None and v[1][0] != "-"]
        s = sorted(f, key=lambda v: packaging.version.parse(v[1]))
        for d, v, r in s:
            if v != "<unknown>":
                print(f"{d}: {v:12s} {r:8s}")
                break
    elif args.summary:
        f = [v for v in versions_list if v[1] is not None and v[1][0] != "-"]
        s = sorted(f, key=lambda v: packaging.version.parse(v[1]))
        current_version = ''
        n_dates = 0
        for d, v, r in s:
            if v == current_version:
                n_dates += 1
            else:
                if n_dates != 0 and filter(current_version):
                    plural = "s" if n_dates > 1 else ""
                    print(f"{current_version}: {n_dates} day{plural}")
                current_version = v
                n_dates = 1
        else:
            if n_dates > 0 and filter(current_version):
                plural = "s" if n_dates > 1 else ""
                print(f"{current_version}: {n_dates} day{plural}")
    else:
        for d, v, r in versions_list:
            if v is not None and filter(v):
                print(f"{d}: {v:12s} {r:8s}")


def make_version_filter(filter_expression):
    def null_filter(version):
        return True

    if filter_expression is None:
        return(null_filter)

    spec = packaging.specifiers.SpecifierSet(filter_expression)

    def filter_function(version):
        return packaging.version.parse(version) in spec


    return(filter_function)


def get_version(date, cursor):
    null_version = "----------"
    null_revision = "--------"
    unknown_version = "<unknown>"
    unknown_revision = "<unknown>"

    year  = date[0:4]
    month = date[4:6]
    day   = date[6:8]
    q = f"select * from MLSO.mlso_numfiles where obs_day='{year}-{month}-{day}';"
    cursor.execute(q)
    row = cursor.fetchone()
    if row is None:
        return(date, None, None)
    else:
        day_id = row[0]

        q = f"select kcor_sw_id from MLSO.kcor_eng where obs_day={day_id} limit 1;"
        cursor.execute(q)
        row = cursor.fetchone()
        if row is None:
            return(date, null_version, null_revision)
        else:
            sw_id = row[0]
            if sw_id is None:
                return(date, unknown_version, unknown_revision)

            q = f"select * from MLSO.kcor_sw where sw_id={sw_id};"
            cursor.execute(q)
            row = cursor.fetchone()
            if row is None:
                return(date, null_version, null_revision)
            else:
                return(date, row[2], row[3])


# ls sub-command
def file_lines(filename):
    n_lines = 0
    
    with open(filename, "r") as f:
        for line in f.readlines():
            n_lines += 1
    return(n_lines)


def get_fits_boolean(header, keyword):
    return(header[keyword] == "in" if keyword in header else False)


def get_fits_float(header, keyword):
    return(header[keyword] if keyword in header else None)


def value2str(v):
    if type(v) == str:
        return(f"{v:10s}")
    elif type(v) == float:
        return(f"{v:8.3f}")
    elif type(v) == int:
        return(f"{v:8d}")
    elif type(v) == bool:
        return(f"{v!s:5s}")
    elif v is None:
        return 5 * "-"
    return(f"{v}")


def list_fits_file(f, columns):
    basename = os.path.basename(f)
    line = f"{basename:36s}"
    with fits.open(f) as fits_file:
        primary_header = fits_file[0].header
        for c in columns:
            v = primary_header[c] if c in primary_header else None
            v = value2str(v)
            line += f"  {v}"
    print(line)


def list_fits_file_default(f):
    basename = os.path.basename(f)
    with fits.open(f) as fits_file:
        header = fits_file[0].header
        diffuser = get_fits_boolean(header, "DIFFUSER")
        calpol = get_fits_boolean(header, "CALPOL")
        darkshutter = get_fits_boolean(header, "DARKSHUT")
        if darkshutter:
            type = "dark"
        elif calpol:
            calpang = header["CALPANG"] if "CALPANG" in header else 0.0
            type = f"cal {calpang:0.1f}°"
        elif diffuser:
            type = "flat"
        else:
            type = "science"
        exposure = get_fits_float(header, "EXPTIME")
        exposure = f"{exposure:0.3f} ms" if exposure is not None else 10 * "-"
        sgsscint = get_fits_float(header, "SGSSCINT")
        seeing = f"{sgsscint:7.3f} arcsec seeing" if sgsscint is not None else 21 * "-"

    print(f"{basename:36s}  {type:10s}  {exposure}  {seeing}")


def list_files(files, columns=None):
    for f in files:
        filename, file_extension = os.path.splitext(f)
        basename = os.path.basename(f)
        if os.path.isdir(f):
            n_subfiles = len(glob.glob(os.path.join(f, "*")))
            name = f"{basename}/"
            print(f"{name:36s}  {n_subfiles:,} files")
        elif os.path.isfile(f):
            if file_extension == ".tgz":
                size = os.stat(f).st_size
                print(f"{basename:36s}  {size:,} bytes")
            else:
                try:
                    if args.columns is None:
                        list_fits_file_default(f)
                    else:
                        list_fits_file(f, columns)
                except OSError:
                    if file_extension in [".log", ".olog", ".txt", ".cfg", ".tarlist"]:
                        n_lines = file_lines(f)
                        s = "s" if n_lines != 1 else ""
                        print(f"{basename:36s}  {n_lines:,} line{s}")
                    else:
                        size = os.stat(f).st_size
                        print(f"{basename:36s}  {size:,} bytes")
        else:
            print(f"{f} - unknown item")


def ls(args):
    if not ls_requirements:
        args.parser.error("missing Python packages required for listing FITS files")

    try:
        files = [f for f in args.files if os.path.isfile(f)]
        dirs = [d for d in args.files if os.path.isdir(d)]
    
        if len(files) == 0 and len(dirs) == 1:
            items = [f for f in glob.glob(os.path.join(dirs[0], "*"))]
            files = [f for f in items if os.path.isfile(f)]
            dirs = [d for d in items if os.path.isdir(d)]
    
        list_files(sorted(dirs))
        list_files(sorted(files), columns=args.columns)
    except KeyboardInterrupt:
        pass


# validate sub-command
def validate(args):
    dates = ",".join(args.dates)

    cmd = [os.path.join(PIPELINE_DIR, "bin", "kcor_verify_dates.sh"),
           args.flags,
           dates]

    process = launch_process(cmd, stdout=None, stderr=subprocess.PIPE)
    print("[%d] %s" % (process.pid, " ".join(cmd)))
            
    terminated = wait_for(process)


# log sub-command
def filter_log(args):
    date_prog = re.compile("^\d{8}$")
    logfiles = [os.path.join(LOG_DIR, f"{f}.{args.type}.log") if date_prog.match(f) else f
                for f in args.logfiles]

    follow = args.follow
    if follow and len(logfiles) > 1:
        print("cannot follow multiple files")
        return

    if args.prune is not None:
        prune_logfiles(logfiles, int(args.prune))
        return

    # default is to not filter
    if args.level:
        level = args.level.upper()
    elif args.critical:
        level = "CRITICAL"
    elif args.error:
        level = "ERROR"
    elif args.warn:
        level = "WARN"
    elif args.info:
        level = "INFO"
    else:
        level = "DEBUG"

    try:
        level_index = LEVELS.index(level)
    except ValueError:
        print("invalid level: %s" % level)
        parser.print_help()
        return

    for i, f in enumerate(logfiles):
        if len(logfiles) > 1:
            if i != 0: print("")
            print(f)
            print("-" * len(f))
        filter_file(f, level_index, follow)


def prune_logfiles(files, max_version):
    version_re = re.compile("\d+")
    for f in files:
        versions = glob.glob(f"{f}.*")
        for v in versions:
            n = v[len(f) + 1:]
            if version_re.match(n):
                if int(n) > max_version:
                    file_to_delete = f"{f}.{n}"
                    print(f"rm {file_to_delete}")
                    os.remove(file_to_delete)


def filter_file(logfile, level_index, follow):
    loglevel_filter = "|".join(LEVELS[level_index:])
    loglevel_prog = re.compile(f".*({loglevel_filter}):.*")
    logstart_prog = re.compile("(\[\d*\] )?\d{4}-\d{2}-\d{2} \d{2}:\d{2}:\d{2}")

    matched_last_line = False

    line = "not empty"

    try:
        with open(logfile, "r") as f:
            while follow or line != "":
                line = f.readline()
                if line == "":
                    try:
                        time.sleep(POLL_SECS)
                    except (IOError, KeyboardInterrupt):
                        return
                    continue

                if loglevel_prog.match(line):
                    matched_last_line = True
                    try:
                        print(line.rstrip())
                    except (IOError, KeyboardInterrupt):
                        return
                else:
                    if matched_last_line:
                        if logstart_prog.match(line):
                            matched_last_line = False
                        else:
                            try:
                                print(line.rstrip())
                            except (IOError, KeyboardInterrupt):
                                return
    except IOError:
        print("Problem reading %s" % logfile)


def wait_for(process):
    try:
        out, err = process.communicate()
        if err != "": print(err)
        return 0
    except KeyboardInterrupt:
        print(f"killing process {process.pid}")
        process.kill()
        return 1


class FakeProcess():
    def __init__(self, pid):
        self.pid = pid

    def kill(self):
        pass

    def communicate(self):
        return ("", "")


def launch_process(cmd, **kwargs):
    if TEST:
        process = FakeProcess(0)
    else:
        process = subprocess.Popen(cmd, encoding="utf-8", **kwargs)
    return process


# calibrate (cal) sub-command
def process_cal(args):
    if args.list is not None:
        if len(args.dates) > 1:
            args.parser.error("only a single date allowed when using list for calibration")
        calibrate_list(args.list, args.dates[0], args.flags, args.no_wait, args.parser)
        return

    for d in args.dates:
        calibrate_dates(d, args.flags, args.no_wait)

    notify_completed(args, "calibration")


def calibrate_list(filelist, dates, flags, no_wait, parser):
    if dates.find(",") >= 0 or dates.find("-") >= 0:
        parser.error("only a single date allowed when using list for calibration")
        return

    cmd = [os.path.join(PIPELINE_DIR, "bin", "runkcor_calibrate_list.sh"),
           flags,
           dates,
           filelist]

    process = launch_process(cmd, stdout=None, stderr=subprocess.PIPE)
    print("[%d] %s" % (process.pid, " ".join(cmd)))
            
    if not no_wait:
        terminated = wait_for(process)


def calibrate_dates(dates, flags, no_wait):
    for d in dates.split(","):
        if d.find("-") < 0:
            cmd = [os.path.join(PIPELINE_DIR, "bin", "runkcor_calibrate.sh"),
                   flags,
                   d]

            process = launch_process(cmd, stdout=None, stderr=subprocess.PIPE)
            print("[%d] %s" % (process.pid, " ".join(cmd)))
            
            if not no_wait:
                terminated = wait_for(process)
                if terminated: break
        else:
            r = d.split("-")
            cmd = [os.path.join(PIPELINE_DIR, "bin", "runkcor_calibrate_range.sh"),
                   flags,
                   r[0],
                   r[1]]

            process = launch_process(cmd, stdout=None, stderr=subprocess.PIPE)
            print("[%d] %s" % (process.pid, " ".join(cmd)))

            if not no_wait:
                terminated = wait_for(process)
                if terminated: break


# process (both rt and eod) sub-command
def process(args):
    for d in args.dates:
        process_dates(d, "process", args.flags, args.no_wait)

    notify_completed(args, "process")


# realtime (rt) sub-command
def process_rt(args):
    for d in args.dates:
        process_dates(d, "rt", args.flags, args.no_wait)

    notify_completed(args, "real-time process")


# end-of-day (eod) sub-command
def process_eod(args):
    for d in args.dates:
        process_dates(d, "eod", args.flags, args.no_wait)

    notify_completed(args, "end-of-day process")


# script sub-command
def run_script(args):
    for dates in args.dates:
        for d in dates.split(","):
            if d.find("-") < 0:
                cmd = [os.path.join(PIPELINE_DIR, "bin", f"runkcor_script.sh"),
                       args.name,
                       args.flags,
                       d]

                process = launch_process(cmd, stdout=None, stderr=subprocess.PIPE)
                print("[%d] %s" % (process.pid, " ".join(cmd)))
                if not args.no_wait:
                    terminated = wait_for(process)
                    if terminated: break
            else:
                r = d.split("-")
                cmd = [os.path.join(PIPELINE_DIR, "bin", f"runkcor_script_range.sh"),
                       args.name,
                       args.flags,
                       r[0], r[1]]

                process = launch_process(cmd, stdout=None, stderr=subprocess.PIPE)
                print("[%d] %s" % (process.pid, " ".join(cmd)))
                if not args.no_wait:
                    terminated = wait_for(process)
                    if terminated: break

    notify_completed(args, "script")


# CME detection sub-command
def cme_detection(args):
    for d in args.dates:
        process_dates(d, "cmedetection", args.flags, args.no_wait)

    notify_completed(args, "CME detection")


# savecme sub-command
def savecme(args):
    script = f"savecme"
    for d in args.dates:
        process_dates(d, script, args.flags, args.no_wait)

    notify_completed(args, "save CME results")


# archive sub-command
def archive(args):
    script = f"archive_l{args.level}"
    for d in args.dates:
        process_dates(d, script, args.flags, args.no_wait)


# purge sub-command
def purge(args):
    for d in args.dates:
        process_dates(d, "purge", args.flags, args.no_wait)

    notify_completed(args, "purge")


# remove sub-command
def remove(args):
    for d in args.dates:
        process_dates(d, "remove", args.flags, args.no_wait)

    notify_completed(args, "remove")


def process_dates(dates, script, flags, no_wait):
    for d in dates.split(","):
        if d.find("-") < 0:
            cmd = [os.path.join(PIPELINE_DIR, "bin", f"runkcor_{script}.sh"),
                   flags,
                   d]

            process = launch_process(cmd, stdout=None, stderr=subprocess.PIPE)
            print("[%d] %s" % (process.pid, " ".join(cmd)))
            if not no_wait:
                terminated = wait_for(process)
                if terminated: break
        else:
            r = d.split("-")
            cmd = [os.path.join(PIPELINE_DIR, "bin", f"runkcor_{script}_range.sh"),
                   flags,
                   r[0], r[1]]

            process = launch_process(cmd, stdout=None, stderr=subprocess.PIPE)
            print("[%d] %s" % (process.pid, " ".join(cmd)))
            if not no_wait:
                terminated = wait_for(process)
                if terminated: break


# simulate sub-command
def simulate(args):
    if len(args.dates) > 1:
        args.parser.error("only a single date allowed when using the simulator")

    config_basename = f"kcor.{args.flags}.cfg"

    # construct config file filename
    config_filename = os.path.join(PIPELINE_DIR, "config", config_basename)

    # read config file to get arguments to launch data/processing simulators
    config = configparser.ConfigParser()
    config.read(config_filename)

    try:
        depot_basedir = config.get("simulator", "depot_basedir")
    except configparser.NoSectionError:
        args.parser.error("depot_basedir not specified")

    raw_basedir = config.get("processing", "raw_basedir")
    raw_dir = os.path.join(raw_basedir, args.dates[0])

    launch_interval = config.get("simulator", "launch_interval", fallback="60.0")

    arrival_interval = config.get("simulator", "arrival_interval", fallback="60.0")
    speedup_factor   = config.get("simulator", "speedup_factor", fallback="1.0")

    # launch processing simulator
    processing_cmd = [os.path.join(PIPELINE_DIR, "bin", "kcor_simulate_processing"),
                      "-f", args.flags,
                      "--frequency", launch_interval,
                      args.dates[0]]
    if args.no_eod:
        processing_cmd.insert(2, "--no-eod")
    processing_process = subprocess.Popen(processing_cmd)

    time.sleep(5.0)

    # launch incoming data simulator
    data_cmd = [os.path.join(PIPELINE_DIR, "bin", "kcor_simulate_data"),
                "-r", raw_dir,
                "-b", arrival_interval,
                "-s", speedup_factor,
                os.path.join(depot_basedir, args.dates[0])]
    data_process = subprocess.Popen(data_cmd)

    try:
        while True:
            time.sleep(1.0)
    except KeyboardInterrupt:
        data_pid = data_process.pid
        proc_pid = processing_process.pid
        print(f"killing data ({data_pid}) and processing ({proc_pid}) processes...")
        processing_process.kill()
        data_process.kill()


# stage sub-command
def stage(args):
    dst = os.path.realpath(args.location)
    print(f"staging to {dst}")

    for e in args.dates:
        for r in e.split(","):
            if r.find("-") < 0:
                dates = [r]
            else:
                try:
                    dates = expand_date_range(r)
                except IndexError:
                    args.parser.error(r"bad date range expression: {r}")

            for d in dates:
                stage_date(args.parser, d, args.flags, dst)

    notify_completed(args, "stage")


def expand_date_range(r):
    ends = r.split("-")
    start_dt = datetime.datetime.strptime(ends[0], "%Y%m%d")
    end_dt = datetime.datetime.strptime(ends[1], "%Y%m%d")

    if end_dt < start_dt:
        raise IndexError

    dates = []

    dt = start_dt
    while dt < end_dt:
        dates.append(dt.strftime("%Y%m%d"))
        dt += datetime.timedelta(days=1)

    return dates


def raw_basedir(date, config_filename):
    """Look for processing/raw_basedir first -- if not found, then use
    processing/routing_file.
    """
    config = configparser.ConfigParser()
    config.read(config_filename)

    try:
        raw_basedir = config.get("processing", "raw_basedir")
        return raw_basedir
    except configparser.NoOptionError:
        routing_file = config.get("processing", "routing_file")
        routing = configparser.ConfigParser()
        routing.read(routing_file)
        date_ranges = routing.options("kcor")
        for r in date_ranges:
            if pathlib.PurePath(date).match(r):
                raw_basedir = routing.get("kcor", r)
                return raw_basedir
        return None


def stage_date(parser, date, flags, dst):
    config_filename = os.path.join(PIPELINE_DIR,
                                   "config",
                                   f"kcor.{flags}.cfg")
    src = raw_basedir(date, config_filename)

    if src is None:
        parser.error("raw basedir not specified")

    date_dir = os.path.join(src, date)
    if os.path.isdir(date_dir):
        try:
            copy_date(date, src, dst)
        except FileNotFoundError:
            print(f"files not found for {date} in {src}")
            #parser.error(f"files not found in {src}")
    else:
        parser.error(f"{date_dir} does not exist")


def copy_date(date, src, dst):
    copy_files(date, src, "*.log", dst)
    copy_files(date, src, "*.fts.gz", dst, verbose=True)


def copy_files(date, src, spec, dst, *, verbose=False):
    files = glob.glob(os.path.join(src, date, "level0", spec))
    if not files:
        files = glob.glob(os.path.join(src, date, spec))
        if not files:
            raise FileNotFoundError

    dst_dir = os.path.join(dst, date)
    if not os.path.isdir(dst_dir):
        os.mkdir(dst_dir)

    if verbose:
        print(f"staging {date} [{src}] ({len(files)} FITS files)...")

    for f in files:
        shutil.copy2(f, dst_dir)


# locate sub-command
def locate(args):
    # get config file
    config_filename = os.path.join(PIPELINE_DIR,
                                   "config",
                                   f"kcor.{args.flags}.cfg")

    if args.dates:
        for e in args.dates:
            for r in e.split(","):
                if r.find("-") < 0:
                    dates = [r]
                else:
                    try:
                        dates = expand_date_range(r)
                    except IndexError:
                        args.parser.error(r"bad date range expression: {r}")
    
                for d in dates:
                    # get raw_basedir
                    raw_bdir = raw_basedir(d, config_filename)
                    print(f"{d}: {raw_bdir}")
    else:
        config = configparser.ConfigParser()
        config.read(config_filename)
        try:
            raw_bdir = config.get("processing", "raw_basedir")
            print(raw_bdir)
        except configparser.NoOptionError:
            routing_file = config.get("processing", "routing_file")
            with open(routing_file, "r") as f:
                print(f.read().strip())


# nrgf sub-command
def nrgf(args):
    cmd = [os.path.join(PIPELINE_DIR, "bin", f"runkcor_nrgf.sh"),
           args.flags,
           args.date[0],
           args.filename]

    process = launch_process(cmd, stdout=None, stderr=subprocess.PIPE)
    print("[%d] %s" % (process.pid, " ".join(cmd)))
    terminated = wait_for(process)


def print_help(args):
    args.parser.print_help()


if __name__ == "__main__":
    name = "KCor pipeline @GIT_VERSION@ [@GIT_REVISION@] (@GIT_BRANCH@)"

    parser = argparse.ArgumentParser(description=name)

    # top-level arguments
    parser.add_argument("-v", "--version",
                        action="version",
                        version=name)

    # show help if no sub-command given
    parser.set_defaults(func=print_help, parser=parser)

    subparsers = parser.add_subparsers(metavar="command")

    date_help = """dates to run on in the form YYYYMMDD including lists (using
                   commas) and ranges (using hyphens where end date is not
                   included)
                """
    flags_help = """FLAGS section of config filename, i.e., file in config/
                    directory matching kcor.FLAGS.cfg will be used"""


    # list sub-command
    list_parser = subparsers.add_parser("list",
                                        help="list KCor processes")
    list_parser.set_defaults(func=list_processes, parser=list_parser)

    # versions sub-command
    versions_parser = subparsers.add_parser("versions", help="list versions")
    versions_parser.add_argument("dates", type=str, nargs="*", help=date_help,
                                 metavar="date-expr")
    versions_parser.add_argument("-f", "--flags", type=str, help=flags_help,
                                 default="latest")
    versions_parser.add_argument("--filter", type=str,
                                 help="expression to filter versions by",
                                 default=None)
    versions_parser.add_argument("-o", "--oldest", action="store_true",
                                 help="set to only display the oldest version")
    versions_parser.add_argument("-s", "--summary", action="store_true",
                                 help="set to display a summary of versions")
    versions_parser.set_defaults(func=versions, parser=versions_parser)

    # ls sub-command
    ls_parser = subparsers.add_parser("ls",
                                      help="list KCor data files")
    ls_parser.add_argument("files", nargs="*",
                           default=".",
                           help="KCor files(s)",
                           metavar="file(s)")
    ls_parser.add_argument("--columns", type=str, nargs="*",
                           help="FITS keyword names to display",
                           default=None)
    ls_parser.set_defaults(func=ls, parser=ls_parser)

    # log sub-command
    log_parser = subparsers.add_parser("log",
                                       help="filter/display log output")
    log_parser.add_argument("logfiles", nargs="*",
                            help="KCor log filename or date",
                            metavar="logfile")
    level_help = "filter level: DEBUG INFO WARN ERROR CRITICAL (default DEBUG)"
    log_parser.add_argument("-l", "--level",
                            help=level_help)
    log_parser.add_argument("-t", "--type", help="type of log: realtime, eod, cme",
                            default="realtime")
    prune_help = "prune rotated logs with versions higher than MAX_VERSION"
    log_parser.add_argument("-p", "--prune",
                            help=prune_help,
                            metavar="MAX_VERSION")
    log_parser.add_argument("-f", "--follow",
                            help="output appended data as file grows",
                            action="store_true")
    log_parser.add_argument("-d", "--debug",
                            help="DEBUG filter level",
                            action="store_true")
    log_parser.add_argument("-i", "--info",
                            help="INFO filter level",
                            action="store_true")
    log_parser.add_argument("-w", "--warn",
                            help="WARN filter level",
                            action="store_true")
    log_parser.add_argument("-e", "--error",
                            help="ERROR filter level",
                            action="store_true")
    log_parser.add_argument("-c", "--critical",
                            help="CRITICAL filter level",
                            action="store_true")
    log_parser.set_defaults(func=filter_log, parser=log_parser)


    # process, eod, rt, cal sub-commands
    process_parser = subparsers.add_parser("process",
                                           help="run realtime/end-of-day pipelines")
    eod_parser = subparsers.add_parser("end-of-day", aliases=["eod"],
                                       help="run end-of-day pipeline")
    rt_parser = subparsers.add_parser("realtime", aliases=["rt"],
                                      help="run realtime pipeline")
    cal_parser = subparsers.add_parser("calibration", aliases=["cal"],
                                       help="run calibration")

    process_parser.add_argument("dates", type=str, nargs="*", help=date_help,
                                metavar="date-expr")
    eod_parser.add_argument("dates", type=str, nargs="*", help=date_help,
                            metavar="date-expr")
    rt_parser.add_argument("dates", type=str, nargs="*", help=date_help,
                            metavar="date-expr")
    cal_parser.add_argument("dates", type=str, nargs="*", help=date_help,
                            metavar="date-expr")

    process_parser.add_argument("-f", "--flags", type=str, help=flags_help,
                                default="latest")
    eod_parser.add_argument("-f", "--flags", type=str, help=flags_help,
                            default="latest")
    rt_parser.add_argument("-f", "--flags", type=str, help=flags_help,
                           default="latest")
    cal_parser.add_argument("-f", "--flags", type=str, help=flags_help,
                            default="latest")

    nowait_help = "set to run all dates simultaneously"
    process_parser.add_argument("--no-wait", action="store_true", help=nowait_help)
    eod_parser.add_argument("--no-wait", action="store_true", help=nowait_help)
    rt_parser.add_argument("--no-wait", action="store_true", help=nowait_help)
    cal_parser.add_argument("--no-wait", action="store_true", help=nowait_help)

    cal_parser.add_argument("-l", "--list",
                            type=str,
                            metavar="LIST_FILENAME",
                            help="""set to a filename containing a list of files
                                    to use to produce the calibration""")

    process_parser.set_defaults(func=process, parser=process_parser)
    eod_parser.set_defaults(func=process_eod, parser=eod_parser)
    rt_parser.set_defaults(func=process_rt, parser=rt_parser)
    cal_parser.set_defaults(func=process_cal, parser=cal_parser)

    # script sub-command
    script_parser = subparsers.add_parser("script",
                                           help="run a given script on days")
    script_parser.add_argument("dates", type=str, nargs="*", help=date_help,
                               metavar="date-expr")
    script_parser.add_argument("-f", "--flags", type=str, help=flags_help,
                               default="latest")
    script_parser.add_argument("-n", "--name", type=str, help="name of script",
                               required=True)
    script_parser.add_argument("--no-wait", action="store_true", help=nowait_help)
    script_parser.set_defaults(func=run_script, parser=script_parser)


    # cme sub-command
    cme_parser = subparsers.add_parser("cme",
                                       help="run CME detection in batch mode")
    cme_parser.add_argument("dates", type=str, nargs="*", help=date_help,
                            metavar="date-expr")
    cme_parser.add_argument("-f", "--flags", type=str, help=flags_help,
                            default="latest")
    cme_parser.add_argument("--no-wait", action="store_true", help=nowait_help)
    cme_parser.set_defaults(func=cme_detection, parser=cme_parser)


    # savecme sub-command
    savecme_parser = subparsers.add_parser("savecme",
                                           help="save CME results")
    savecme_parser.add_argument("dates", type=str, nargs="*", help=date_help,
                                metavar="date-expr")
    savecme_parser.add_argument("-f", "--flags", type=str, help=flags_help,
                                default="latest")
    savecme_parser.add_argument("--no-wait", action="store_true", help=nowait_help)
    savecme_parser.set_defaults(func=savecme, parser=savecme_parser)


    # archive sub-command
    archive_parser = subparsers.add_parser("archive",
                                           help="archive files to HPSS")
    archive_parser.add_argument("dates", type=str, nargs="*", help=date_help,
                                metavar="date-expr")
    archive_parser.add_argument("-f", "--flags", type=str, help=flags_help,
                                default="latest")
    archive_parser.add_argument("-l", "--level", type=str,
                                help="level to archive, 0 or 1 (1.5), default=0",
                                default="0")
    archive_parser.add_argument("--no-wait", action="store_true", help=nowait_help)
    archive_parser.set_defaults(func=archive, parser=archive_parser)


    # validate sub-command
    validate_parser = subparsers.add_parser("validate",
                                            help="validate previously processed dates")
    validate_parser.add_argument("dates", type=str, nargs="*", help=date_help,
                                 metavar="date-expr")

    validate_parser.add_argument("-f", "--flags", type=str, help=flags_help,
                                 default="latest")
    validate_parser.set_defaults(func=validate, parser=validate_parser)


    # purge sub-command
    purge_help = "purge results from archive/database for a day"
    purge_parser = subparsers.add_parser("purge", help=purge_help)
    purge_parser.add_argument("dates", type=str, nargs="*", help=date_help,
                              metavar="date-expr")
    purge_parser.add_argument("-f", "--flags", type=str, help=flags_help,
                              default="latest")
    purge_parser.add_argument("--no-wait", action="store_true", help=nowait_help)
    purge_parser.set_defaults(func=purge, parser=purge_parser)


    # remove sub-command
    remove_help = "remove raw/level1 directory for a day"
    remove_parser = subparsers.add_parser("remove", help=remove_help)
    remove_parser.add_argument("dates", type=str, nargs="*", help=date_help,
                               metavar="date-expr")
    remove_parser.add_argument("-f", "--flags", type=str, help=flags_help,
                              default="latest")
    remove_parser.add_argument("--no-wait", action="store_true", help=nowait_help)
    remove_parser.set_defaults(func=remove, parser=remove_parser)


    # simulate sub-command
    simulate_parser = subparsers.add_parser("simulate", aliases=["sim"],
                                            help="simulate realtime processing")
    simulate_parser.add_argument("dates", type=str, nargs="*",
                                 help="date to run on in the form YYYYMMDD",
                                 metavar="date")
    simulate_parser.add_argument("-f", "--flags", type=str, help=flags_help,
                                default="latest")
    simulate_parser.add_argument("--no-eod", action="store_true",
                                 help="set to not launch end-of-day processing")
    simulate_parser.set_defaults(func=simulate, parser=simulate_parser)


    # stage sub-command
    stage_parser = subparsers.add_parser("stage",
                                         help="stage raw data")
    stage_parser.add_argument("dates", type=str, nargs="*",
                              help="date to run on in the form YYYYMMDD",
                              metavar="date")
    stage_parser.add_argument("-f", "--flags", type=str, help=flags_help,
                              default="reprocess")
    stage_parser.add_argument("-l", "--location", type=str,
                              help="location to copy raw data to",
                              default=".")
    stage_parser.set_defaults(func=stage, parser=stage_parser)


    # locate sub-command
    locate_parser = subparsers.add_parser("locate", aliases=["loc"],
                                          help="locate raw data")
    locate_parser.add_argument("dates", type=str, nargs="*",
                              help="date to run on in the form YYYYMMDD",
                              metavar="date")
    locate_parser.add_argument("-f", "--flags", type=str, help=flags_help,
                               default="reprocess")
    locate_parser.set_defaults(func=locate, parser=locate_parser)

    # nrgf sub-command
    nrgf_parser = subparsers.add_parser("nrgf",
                                          help="process a L0 file to a NRGF")
    nrgf_parser.add_argument("date", type=str, nargs="*",
                              help="date to run on in the form YYYYMMDD",
                              metavar="date")
    nrgf_parser.add_argument("-f", "--flags", type=str, help=flags_help,
                               default="latest")
    nrgf_parser.add_argument("--filename", type=str, help="L0 basename to process")
    nrgf_parser.set_defaults(func=nrgf, parser=nrgf_parser)

    # parse args and call appropriate sub-command
    args = parser.parse_args()
    args.func(args)
